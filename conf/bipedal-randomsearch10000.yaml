---

# An example illustrating how QD algorithms can automatically discover the feature descriptors of a Grid container.
# Here we use a methodology similar to the AURORA algorithm (Cully2019: https://arxiv.org/pdf/1905.11874.pdf) where an autoencoder is continuously trained during the optimization process on all individuals found so far. The latent space of this autoencoder is used as the feature descriptors of the grid.
# In order to achieve that, grids have to periodically recompute the feature descriptors of all individual found so far. So it implies that all individuals should be stored in additional container. This is achieved in QDpy by using hierarchies of containers, where a (child) container can forward all individuals it encounters to a parent container. Here, the child container is the main Grid, and the parent is an archive containing all individuals found so far.
# Latent spaces of different autoencoders tend to have different domains (e.g. one autoencoder would operate in the [-1., 1.] domain, another on [-5., -1.]) even when they were trained on the same dataset. As such, we use AutoScalingGrid containers instead of just Grid. Such containers periodically adjust their feature descriptors domains to match all previously encountered individuals.


# The random seed
seed: 2323

batch_mode: False
send_several_suggestions_to_fn: True
max_nb_suggestions_per_call: 10

# Type of experiment
experiment_type: bipedal_walker
debug_features: False # set to True to determine feature domain bounds
indv_eps: 5       # episodes per individual
max_episode_length: 300



fitness_type: "meanAvgReward"
meanAvgRewardDomain: [-200., 350.]

#features_list: ["meanDistance", "meanHeadStability"]
#meanDistanceDomain: [0., 50.]
#meanHeadStabilityDomain: [0., 2.5]
#meanTorquePerStepDomain: [0., 25.]
#meanJumpDomain: [0., 0.75]
#meanLeg0HipAngleDomain: [0., 2.5]
#meanLeg0HipSpeedDomain: [0., 10.]
#meanLeg0KneeAngleDomain: [0., 2.5]
#meanLeg0KneeSpeedDomain: [0., 10.]
#meanLeg1HipAngleDomain: [0., 2.5]
#meanLeg1HipSpeedDomain: [0., 10.]
#meanLeg1KneeAngleDomain: [0., 2.5]
#meanLeg1KneeSpeedDomain: [0., 10.]


game: 
    env_name: 'BipedalWalker-v2'
    input_size: 24
    output_size: 4
    time_factor: 0
    layers: [40, 40]
    activation: 'tanh'
    noise_bias: 0.0
    output_noise: [False, False, False]
    rnn_mode: False



# The name of the main algorithm (see below the description of 'algoQD')
main_algorithm_name: algo1

to_grid_parameters:
    max_items_per_bin: 1                              # The number of items in each bin of the grid
    shape: [25, 25]                                   # The number of bins for each feature


# The list of all container.
containers:

    # Grid parameters
    max_items_per_bin: 1                              # The number of items in each bin of the grid
    #fitness_scaling: False                            # Whether to autoscale the fitness or not
    #features_scaling: True                            # Whether to autoscale the features or not
    #rescaling_period: 1000                            # When to perform the autoscaling operation. Here it's done every time 1000 individuals are added.
    shape: [25, 25]                                   # The number of bins for each feature



    parentContainer:                             # We create a container that will contain ALL tested individuals
        type: Container                          # A simple container, that will store ALL added individuals that are within bounds
        #storage_type: orderedset                 # Faster than 'list' for large container
        storage_type: indexableset              # Faster than 'orderedset' but may have compatibility problems with pickle in some versions
        fitness_domain:
        features_domain:



# The list of all algorithms
algorithms:
    # Default parameter values for each algorithm
    #optimisation_task: minimisation   # We perform maximisation of all fitness objectives
    #dimension: 5                      # The number of dimensions of the problem. For rastrigin, any dimension >= 2 can be chosen
    #ind_domain: [0.1, 0.9]              # The domain of each value of the genome (optional)

    # Evolution parameters
    batch_size: 1000 #0     # The number of evaluations in each subsequent batch
    sel_pb: 0.0 # 1.0         # The probability of performing selection+variation instead of initialising a new genome
    init_pb: 1.0 # 0.0        # The probability of initiating a new genome instead of performing selection
    mut_pb: 0.4 # 0.1         # The probability of mutating each value of the genome of a selected individual
    eta: 20. # 10           # The ETA parameter of the polynomial mutation (as defined in the origin NSGA-II paper by Deb.). It corresponds to the crowding degree of the mutation. A high ETA will produce mutants close to its parent, a small ETA will produce offspring with more changes.


    algo1:
        type: RandomSearchMutPolyBounded
        container: parentContainer                  # The container to use to store individuals told to the optimisers
        budget: 10000


# MODELINE "{{{1
# vim:expandtab:softtabstop=4:shiftwidth=4:fileencoding=utf-8
# vim:foldmethod=marker
