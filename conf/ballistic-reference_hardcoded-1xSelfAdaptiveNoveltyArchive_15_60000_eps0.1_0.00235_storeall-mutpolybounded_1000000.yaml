---

# An example illustrating how QD algorithms can automatically discover the feature descriptors of a Grid container.
# Here we use a methodology similar to the AURORA algorithm (Cully2019: https://arxiv.org/pdf/1905.11874.pdf) where an autoencoder is continuously trained during the optimization process on all individuals found so far. The latent space of this autoencoder is used as the feature descriptors of the grid.
# In order to achieve that, grids have to periodically recompute the feature descriptors of all individual found so far. So it implies that all individuals should be stored in additional container. This is achieved in QDpy by using hierarchies of containers, where a (child) container can forward all individuals it encounters to a parent container. Here, the child container is the main Grid, and the parent is an archive containing all individuals found so far.
# Latent spaces of different autoencoders tend to have different domains (e.g. one autoencoder would operate in the [-1., 1.] domain, another on [-5., -1.]) even when they were trained on the same dataset. As such, we use AutoScalingGrid containers instead of just Grid. Such containers periodically adjust their feature descriptors domains to match all previously encountered individuals.


# The random seed
#seed: 2323

batch_mode: True
#send_several_suggestions_to_fn: True
#max_nb_suggestions_per_call: 10

# Type of experiment
experiment_type: ballistic
nb_features: 2

# KLC
klc_reference_data_file: data/ballistic-100000.p
klc_scores_names: ["hardcoded0", "hardcoded1"]
klc_nb_bins: 30
klc_epsilon: 1e-20


# The name of the main algorithm (see below the description of 'algoQD')
main_algorithm_name: algo1

to_grid_parameters:
    max_items_per_bin: 1                              # The number of items in each bin of the grid
    shape: [25, 25]                                   # The number of bins for each feature


# The list of all container.
containers:

    # Novelty Archive parameters
    k: 15
    k_resolution: 60000 # 3000
    threshold_novelty: 0.002350432090367377 # 0.01 # 0.1
    epsilon_dominance: True
    epsilon: 0.1
    rebalancing_period: 0
    compute_new_threshold_period: 0


    parentContainer:                             # We create a container that will contain ALL tested individuals
        type: Container                          # A simple container, that will store ALL added individuals that are within bounds
        name: parentContainer                    # The name of the container. Optional. Default to the parent key (here also 'cont0')
        #storage_type: orderedset                 # Faster than 'list' for large container
        storage_type: indexableset              # Faster than 'orderedset' but may have compatibility problems with pickle in some versions
        fitness_domain:
        features_domain:

    cont1:                                                # The main grid container
        type: SelfAdaptiveNoveltyArchive                             # The type of the container. Here we use an AutoScalingGrid that periodically adjust the feature descriptors domains to match the individuals encountered so far
        parents: [parentContainer]                        # The list of parent containers. Every individual added to `cont0` will be also forwarded to the parents
        scaling_containers: [parentContainer]             # The list of containers used to store individuals added after a rescaling operation. If empty, will use the parents instead.
        fitness_domain: [[0., 1.]]                             # The domain of each fitness objective (here we only have one objective)
        features_domain: [[-2., 2.], [-2., 2.]]             # The initial domain of each feature. Must be specified here even if the container will autoscale the domains, to set the number of features
        only_add_accepted_inds_to_parents: False
        features_score_names: ["hardcoded0", "hardcoded1"]
        storage_type: indexableset              # Faster than 'orderedset' but may have compatibility problems with pickle in some versions


# The list of all algorithms
algorithms:
    # Default parameter values for each algorithm
    #optimisation_task: minimisation   # We perform maximisation of all fitness objectives
    #dimension: 5                      # The number of dimensions of the problem. For rastrigin, any dimension >= 2 can be chosen
    #ind_domain: [0.1, 0.9]              # The domain of each value of the genome (optional)


    # Then, we use an evolutionary algorithm that perform random search and polynomial mutations. This algorithm makes a trade-off between quality (finding good performing solutions) and diversity (find solutions corresponding to each bin of the grid)
    algo1:
        type: RandomSearchMutPolyBounded
        #type: ScoreProportionateRouletteMutPolyBounded
        container: cont1                  # The container to use to store individuals told to the optimisers
        budget: 1000000       # The total number of allowed evaluations for this algorithm
        # Evolution parameters
        batch_size: 200     # The number of evaluations in each subsequent batch
        sel_pb: 0.5 # 1.0         # The probability of performing selection+variation instead of initialising a new genome
        init_pb: 0.5 # 0.0        # The probability of initiating a new genome instead of performing selection
        mut_pb: 1.0 # 0.1         # The probability of mutating each value of the genome of a selected individual
        eta: 10. # 10           # The ETA parameter of the polynomial mutation (as defined in the origin NSGA-II paper by Deb.). It corresponds to the crowding degree of the mutation. A high ETA will produce mutants close to its parent, a small ETA will produce offspring with more changes.



# MODELINE "{{{1
# vim:expandtab:softtabstop=4:shiftwidth=4:fileencoding=utf-8
# vim:foldmethod=marker
